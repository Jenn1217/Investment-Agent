{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2931c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8dc3b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('source/raw-news/df_5.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1708363",
   "metadata": {},
   "source": [
    "# 新闻数据清洗\n",
    "\n",
    "去掉重复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37acca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e42d6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CREAT_TM', 'UPDT_TM', 'IS_VLD', 'F4000', 'F4001', 'F4003', 'F4004', 'F4020', 'F4022', 'F4023', 'F4024', 'F4025', 'F4026', 'F4027']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f831babd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_map = {\n",
    "    \"F4000\": \"news_id\",\n",
    "    \"F4003\": \"publish_time\",\n",
    "    \"F4001\": \"title\",\n",
    "    \"F4004\": \"source\",\n",
    "    \"F4020\": \"content\",\n",
    "    \"F4022\": \"news_type\",\n",
    "    \"F4023\": \"source_id\",\n",
    "    \"F4024\": \"info_source\",\n",
    "    \"F4025\": \"source_category\",\n",
    "    \"F4026\": \"url\",\n",
    "    \"F4027\": \"summary\"\n",
    "}\n",
    "\n",
    "df = df.rename(columns=rename_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70f5ebe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              CREAT_TM              UPDT_TM  IS_VLD  news_id  \\\n",
      "0  2025-04-02 16:07:33  2025-04-02 16:07:33       1        3   \n",
      "1  2025-04-02 16:07:33  2025-04-02 16:07:33       1        4   \n",
      "2  2025-04-02 16:07:33  2025-04-02 16:07:33       1        5   \n",
      "3  2025-04-02 16:07:33  2025-04-02 16:07:33       1        6   \n",
      "4  2025-04-02 16:07:33  2025-04-02 16:07:33       1        7   \n",
      "\n",
      "                              title         publish_time       source  \\\n",
      "0            3月基金发行回暖 单月发行份额超1000亿份  2025-04-02 15:45:02        证券时报网   \n",
      "1     4月首缕“春风”吹到医药股：全线爆发 后续行情持续性几何？  2025-04-02 15:44:02     21世纪经济报道   \n",
      "2      联博智远混合将于4月7日发售 以均衡策略把握A股长期机遇  2025-04-02 15:30:47    中国证券报·中证网   \n",
      "3  ETF今日收评 | 新兴亚洲ETF涨超5% 新经济ETF跌超5%  2025-04-02 15:17:56       每日经济新闻   \n",
      "4                   联博基金旗下第二只产品即将发行  2025-04-02 14:45:12  上海证券报·中国证券网   \n",
      "\n",
      "                                             content  news_type  \\\n",
      "0  股市回暖背景下，权益类基金发行拾级而上。公募排排网数据显示，截至3月31日，按基金成立日统计...          2   \n",
      "1  医药终于领涨了。二季度开局，医药股一马当先展现出强势上涨姿态。4月1日，医药生物行业全线爆发...          2   \n",
      "2  中证报中证网讯（王珞）联博基金4月2日宣布，旗下第二只公募产品——联博智远混合型证券投资基金...          2   \n",
      "3  市场全天冲高回落，三大指数微幅上涨。从板块来看，机器人概念股再度走强，烟草概念股表现活跃。下...          2   \n",
      "4  上证报中国证券网讯（记者王彭）4月2日，联博基金管理有限公司（以下简称“联博基金”）宣布，旗...          2   \n",
      "\n",
      "              source_id info_source source_category  url  summary  \n",
      "0  NW202504023363543852   eastmoney   fund-dynamics  NaN      NaN  \n",
      "1  NW202504023363542876   eastmoney   fund-dynamics  NaN      NaN  \n",
      "2  NW202504023363531572   eastmoney   fund-dynamics  NaN      NaN  \n",
      "3  NW202504023363516739   eastmoney   fund-dynamics  NaN      NaN  \n",
      "4  NW202504023363498635   eastmoney   fund-dynamics  NaN      NaN  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40c432ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import test_qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18383133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [1] 正在测试 Dify 网络连通性 ---\n",
      "基础 URL 请求状态码: 404\n",
      "\n",
      "--- [2] 正在调用封装后的 call_dify_api ---\n",
      "\n",
      "✅ 调用成功!\n",
      "模型回复: 你好！我是通义千问（Qwen），由通义实验室研发的大语言模型。我并非通过封装后的函数调用，而是直接以模型身份与你进行对话。我的设计目标是理解并生成自然语言，能够回答问题、创作文字、提供信息查询等。如果你有任何问题或需要帮助，欢迎随时告诉我！\n",
      "Conversation ID: ef201dd5-87a5-4fff-9b54-4d7230726931\n"
     ]
    }
   ],
   "source": [
    "test_qwen.test_dify_connectivity()\n",
    "    \n",
    "    # 2. 调用封装好的函数\n",
    "print(\"\\n--- [2] 正在调用封装后的 call_dify_api ---\")\n",
    "test_query = \"你好，请确认你是通过封装后的函数调用的，并简要自我介绍。\"\n",
    "    \n",
    "result = test_qwen.call_dify_api(test_query)\n",
    "    \n",
    "if \"answer\" in result:\n",
    "    print(\"\\n✅ 调用成功!\")\n",
    "    print(f\"模型回复: {result['answer']}\")\n",
    "    print(f\"Conversation ID: {result.get('conversation_id')}\")\n",
    "else:\n",
    "    print(\"\\n❌ 调用失败或返回异常\")\n",
    "    print(f\"结果详情: {json.dumps(result, ensure_ascii=False, indent=2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a84ec13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型回复: 你好！我是通义千问（Qwen），由通义实验室研发的大语言模型。我并非通过封装后的函数调用，而是直接以模型身份与你进行对话。我的设计目标是理解并生成人类语言，能够回答问题、创作文字、提供信息查询等。如果你有任何问题或需要帮助，欢迎随时告诉我！\n",
      "Conversation ID: 56a8a74a-0dc0-497c-afbc-4fe75913caf1\n"
     ]
    }
   ],
   "source": [
    "test_query = \"你好，请确认你是通过封装后的函数调用的，并简要自我介绍。\"\n",
    "    \n",
    "result = test_qwen.call_dify_api(test_query)\n",
    "print(f\"模型回复: {result['answer']}\")\n",
    "print(f\"Conversation ID: {result.get('conversation_id')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a98deb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rapidfuzz\n",
      "  Using cached rapidfuzz-3.14.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Using cached rapidfuzz-3.14.3-cp312-cp312-macosx_11_0_arm64.whl (1.4 MB)\n",
      "Installing collected packages: rapidfuzz\n",
      "Successfully installed rapidfuzz-3.14.3\n"
     ]
    }
   ],
   "source": [
    "!pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9808836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# ----------------------------\n",
    "# 0) 加载你的三张词表\n",
    "# ----------------------------\n",
    "def load_taxonomies(\n",
    "    company_csv: str = \"source/industry/company-listcsv.csv\",\n",
    "    concept_csv: str = \"source/industry/concept-list.csv\",\n",
    "    industry_csv: str = \"source/industry/industry-list.csv\",\n",
    "):\n",
    "    df_c = pd.read_csv(company_csv)\n",
    "    df_k = pd.read_csv(concept_csv)\n",
    "    df_i = pd.read_csv(industry_csv)\n",
    "\n",
    "    # 兼容列名：FullName / 中文全称\n",
    "    if \"FullName\" in df_c.columns:\n",
    "        name_col = \"FullName\"\n",
    "    elif \"中文全称\" in df_c.columns:\n",
    "        name_col = \"中文全称\"\n",
    "    else:\n",
    "        raise ValueError(f\"公司表找不到 FullName/中文全称 列，实际列：{df_c.columns.tolist()}\")\n",
    "\n",
    "    # 兼容股票代码列：Symbol / 股票代码\n",
    "    if \"Symbol\" in df_c.columns:\n",
    "        code_col = \"Symbol\"\n",
    "    elif \"股票代码\" in df_c.columns:\n",
    "        code_col = \"股票代码\"\n",
    "    else:\n",
    "        code_col = None  # 不强制\n",
    "\n",
    "    companies = []\n",
    "    for _, r in df_c.iterrows():\n",
    "        full = str(r[name_col]).strip()\n",
    "        if not full or full == \"nan\":\n",
    "            continue\n",
    "        companies.append({\n",
    "            \"full_name\": full,\n",
    "            \"code\": (str(r[code_col]).strip() if code_col and pd.notna(r[code_col]) else None)\n",
    "        })\n",
    "\n",
    "    concepts = []\n",
    "    for _, r in df_k.iterrows():\n",
    "        concepts.append({\n",
    "            \"code\": str(r[\"conceptCode\"]).strip(),\n",
    "            \"name\": str(r[\"conceptName\"]).strip()\n",
    "        })\n",
    "\n",
    "    industries = []\n",
    "    for _, r in df_i.iterrows():\n",
    "        industries.append({\n",
    "            \"code\": str(r[\"industryCode\"]).strip(),\n",
    "            \"name\": str(r[\"industryName\"]).strip(),\n",
    "            \"level\": int(r[\"industryLevel\"]) if \"industryLevel\" in df_i.columns and pd.notna(r[\"industryLevel\"]) else None\n",
    "        })\n",
    "\n",
    "    return companies, concepts, industries\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 1) 公司名归一化：用来把简称映射回全称\n",
    "# ----------------------------\n",
    "_COMMON_SUFFIX = [\n",
    "    \"股份有限公司\", \"有限公司\", \"集团股份有限公司\", \"集团有限公司\",\n",
    "    \"集团\", \"股份\", \"有限责任公司\", \"公司\"\n",
    "]\n",
    "\n",
    "def normalize_company_name(s: str) -> str:\n",
    "    s = re.sub(r\"\\s+\", \"\", s)\n",
    "    # 去掉常见后缀\n",
    "    for suf in _COMMON_SUFFIX:\n",
    "        if s.endswith(suf) and len(s) > len(suf):\n",
    "            s = s[:-len(suf)]\n",
    "            break\n",
    "    # 去括号内容（有些简称带括号）\n",
    "    s = re.sub(r\"[（(].*?[）)]\", \"\", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def build_company_index(companies):\n",
    "    \"\"\"\n",
    "    建两个索引：\n",
    "    - full_name_set：用于直接全称命中\n",
    "    - norm_to_full：归一名 -> 多个全称（可能冲突）\n",
    "    - norm_list：所有归一名列表（用于模糊匹配）\n",
    "    \"\"\"\n",
    "    full_name_set = set()\n",
    "    norm_to_full = {}\n",
    "    for c in companies:\n",
    "        full = c[\"full_name\"]\n",
    "        full_name_set.add(full)\n",
    "        norm = normalize_company_name(full)\n",
    "        norm_to_full.setdefault(norm, []).append(c)\n",
    "\n",
    "    norm_list = list(norm_to_full.keys())\n",
    "    return full_name_set, norm_to_full, norm_list\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2) 本地抽行业/概念：直接词典匹配（简单稳）\n",
    "# ----------------------------\n",
    "def dict_match(text: str, items, key_name=\"name\", max_hits=20):\n",
    "    hits = []\n",
    "    for it in items:\n",
    "        name = it[key_name]\n",
    "        if name and name in text:\n",
    "            hits.append(it)\n",
    "            if len(hits) >= max_hits:\n",
    "                break\n",
    "    return hits\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3) 本地抽人名（粗召回）：职位触发词 + 2~4字中文名\n",
    "# ----------------------------\n",
    "_TITLE_TRIG = r\"(董事长|总经理|CEO|CFO|总裁|行长|董事|副总经理|负责人|发言人|总监|首席科学家|院士)\"\n",
    "def extract_persons_rule(text: str, max_hits=10):\n",
    "    persons = []\n",
    "    for m in re.finditer(_TITLE_TRIG, text):\n",
    "        start = max(0, m.start() - 6)\n",
    "        end = min(len(text), m.end() + 10)\n",
    "        window = text[start:end]\n",
    "        # 在职位附近找 2~4 个汉字的人名\n",
    "        nm = re.search(r\"([\\u4e00-\\u9fff]{2,4})\" + m.group(0), window)\n",
    "        if nm:\n",
    "            persons.append({\n",
    "                \"name\": nm.group(1),\n",
    "                \"title\": m.group(0),\n",
    "                \"organization\": None,\n",
    "                \"relevance\": 0.5,\n",
    "                \"evidence\": [window]\n",
    "            })\n",
    "        if len(persons) >= max_hits:\n",
    "            break\n",
    "    return persons\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 4) 模型辅助：只让模型吐出“表面名/surface forms”\n",
    "#    不让它做映射（映射交给本地，避免胡编）\n",
    "# ----------------------------\n",
    "def llm_suggest_surface_entities(call_dify_api, content: str):\n",
    "    prompt = f\"\"\"\n",
    "你是信息抽取器。只基于文本，抽取“表面出现”的实体，不要猜测不在文本里的信息。\n",
    "输出严格 JSON（不要多余文字），格式如下：\n",
    "{{\n",
    "  \"company_surface\": [\"在文本中出现的公司简称/全称/机构名\", \"...\"],\n",
    "  \"person_surface\": [\"在文本中出现的人名\", \"...\"]\n",
    "}}\n",
    "\n",
    "文本：\n",
    "{content}\n",
    "\"\"\".strip()\n",
    "\n",
    "    resp = call_dify_api(prompt)\n",
    "    ans = resp.get(\"answer\", \"\")\n",
    "    try:\n",
    "        return json.loads(ans)\n",
    "    except Exception:\n",
    "        return {\"company_surface\": [], \"person_surface\": []}\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 5) 把 surface company 映射回你公司全称（核心）\n",
    "# ----------------------------\n",
    "def map_surface_to_full(surface_names, full_name_set, norm_to_full, norm_list,\n",
    "                        score_threshold=88, topk=3):\n",
    "    \"\"\"\n",
    "    先：如果 surface 直接就是全称 -> 命中\n",
    "    再：归一化 exact -> 命中\n",
    "    再：模糊匹配到最像的归一名 -> 命中（阈值控制）\n",
    "    \"\"\"\n",
    "    mapped = []\n",
    "    seen_full = set()\n",
    "\n",
    "    for s in surface_names:\n",
    "        if not s or s == \"nan\":\n",
    "            continue\n",
    "        s = str(s).strip()\n",
    "        if len(s) < 2:\n",
    "            continue\n",
    "\n",
    "        # 1) 全称直接命中\n",
    "        if s in full_name_set:\n",
    "            cand_list = [c for c in norm_to_full.get(normalize_company_name(s), []) if c[\"full_name\"] == s]\n",
    "            c = cand_list[0] if cand_list else {\"full_name\": s, \"code\": None}\n",
    "            if c[\"full_name\"] not in seen_full:\n",
    "                mapped.append((c, 1.0, s))\n",
    "                seen_full.add(c[\"full_name\"])\n",
    "            continue\n",
    "\n",
    "        # 2) 归一化 exact\n",
    "        sn = normalize_company_name(s)\n",
    "        if sn in norm_to_full:\n",
    "            # 如果同一个归一名对应多个公司，就先都放进去（或者你可再加 disambiguation）\n",
    "            for c in norm_to_full[sn]:\n",
    "                if c[\"full_name\"] not in seen_full:\n",
    "                    mapped.append((c, 0.95, s))\n",
    "                    seen_full.add(c[\"full_name\"])\n",
    "            continue\n",
    "\n",
    "        # 3) 模糊匹配到“归一名”\n",
    "        best = process.extractOne(sn, norm_list, scorer=fuzz.WRatio)\n",
    "        if best:\n",
    "            best_norm, best_score, _ = best\n",
    "            if best_score >= score_threshold:\n",
    "                for c in norm_to_full[best_norm][:topk]:\n",
    "                    if c[\"full_name\"] not in seen_full:\n",
    "                        mapped.append((c, best_score / 100.0, s))\n",
    "                        seen_full.add(c[\"full_name\"])\n",
    "\n",
    "    return mapped\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 6) 最终：从 df['content'] 抽 entities（你要的主函数）\n",
    "# ----------------------------\n",
    "def extract_entities_from_content(\n",
    "    call_dify_api,\n",
    "    content: str,\n",
    "    companies, concepts, industries,\n",
    "    full_name_set, norm_to_full, norm_list,\n",
    "):\n",
    "    # ① 本地：行业/概念（直接词典命中）\n",
    "    concept_hits = dict_match(content, concepts, key_name=\"name\")\n",
    "    industry_hits = dict_match(content, industries, key_name=\"name\")\n",
    "\n",
    "    # ② 本地：公司全称直接命中（很少，但免费）\n",
    "    full_hits = [c for c in companies if c[\"full_name\"] in content][:30]\n",
    "\n",
    "    # ③ 本地：人名规则召回\n",
    "    persons_rule = extract_persons_rule(content)\n",
    "\n",
    "    # ④ 模型：补公司简称/机构表面名、人名表面名\n",
    "    sug = llm_suggest_surface_entities(call_dify_api, content)\n",
    "    company_surface = list(dict.fromkeys(sug.get(\"company_surface\", [])))  # 去重保序\n",
    "    person_surface = list(dict.fromkeys(sug.get(\"person_surface\", [])))\n",
    "\n",
    "    # ⑤ 映射：简称 -> 全称（关键）\n",
    "    mapped = map_surface_to_full(company_surface, full_name_set, norm_to_full, norm_list)\n",
    "\n",
    "    # ⑥ 拼 entities（保持你之前 JSON 格式）\n",
    "    entities = {\n",
    "        \"companies\": [],\n",
    "        \"persons\": [],\n",
    "        \"industries\": [],\n",
    "        \"concepts\": []\n",
    "    }\n",
    "\n",
    "    # 公司：合并 full_hits + mapped\n",
    "    # full_hits 也按相同结构输出\n",
    "    seen = set()\n",
    "    for c in full_hits:\n",
    "        if c[\"full_name\"] in seen:\n",
    "            continue\n",
    "        entities[\"companies\"].append({\n",
    "            \"name\": c[\"full_name\"],\n",
    "            \"code\": c.get(\"code\"),\n",
    "            \"role\": \"related\",\n",
    "            \"relevance\": 0.9,\n",
    "            \"mentions\": content.count(c[\"full_name\"]),\n",
    "            \"evidence\": [c[\"full_name\"]]\n",
    "        })\n",
    "        seen.add(c[\"full_name\"])\n",
    "\n",
    "    for c, rel, surface in mapped:\n",
    "        if c[\"full_name\"] in seen:\n",
    "            continue\n",
    "        entities[\"companies\"].append({\n",
    "            \"name\": c[\"full_name\"],\n",
    "            \"code\": c.get(\"code\"),\n",
    "            \"role\": \"related\",\n",
    "            \"relevance\": float(rel),\n",
    "            \"mentions\": content.count(surface) if surface else None,\n",
    "            \"evidence\": [surface]\n",
    "        })\n",
    "        seen.add(c[\"full_name\"])\n",
    "\n",
    "    # 人物：规则 + 模型表面名（表面名也先塞进去，后续你可再清洗）\n",
    "    seen_p = set()\n",
    "    for p in persons_rule:\n",
    "        k = (p[\"name\"], p[\"title\"])\n",
    "        if k in seen_p:\n",
    "            continue\n",
    "        entities[\"persons\"].append(p)\n",
    "        seen_p.add(k)\n",
    "\n",
    "    for pn in person_surface[:10]:\n",
    "        if not pn or len(pn) < 2:\n",
    "            continue\n",
    "        entities[\"persons\"].append({\n",
    "            \"name\": pn,\n",
    "            \"title\": None,\n",
    "            \"organization\": None,\n",
    "            \"relevance\": 0.4,\n",
    "            \"evidence\": [pn]\n",
    "        })\n",
    "\n",
    "    # 行业/概念\n",
    "    for it in industry_hits:\n",
    "        entities[\"industries\"].append({\n",
    "            \"name\": it[\"name\"],\n",
    "            \"code\": it[\"code\"],\n",
    "            \"relevance\": 0.8\n",
    "        })\n",
    "\n",
    "    for it in concept_hits:\n",
    "        entities[\"concepts\"].append({\n",
    "            \"name\": it[\"name\"],\n",
    "            \"code\": it[\"code\"],\n",
    "            \"relevance\": 0.8\n",
    "        })\n",
    "\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e78b8982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"entities\": {\n",
      "    \"companies\": [\n",
      "      {\n",
      "        \"name\": \"深圳市中金岭南有色金属股份有限公司\",\n",
      "        \"code\": \"000060\",\n",
      "        \"role\": \"related\",\n",
      "        \"relevance\": 0.9,\n",
      "        \"mentions\": 2,\n",
      "        \"evidence\": [\n",
      "          \"中金公司\"\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"东方证券股份有限公司\",\n",
      "        \"code\": \"600958\",\n",
      "        \"role\": \"related\",\n",
      "        \"relevance\": 0.95,\n",
      "        \"mentions\": 1,\n",
      "        \"evidence\": [\n",
      "          \"东方证券\"\n",
      "        ]\n",
      "      }\n",
      "    ],\n",
      "    \"persons\": [],\n",
      "    \"industries\": [\n",
      "      {\n",
      "        \"name\": \"机器人\",\n",
      "        \"code\": \"640701\",\n",
      "        \"relevance\": 0.8\n",
      "      }\n",
      "    ],\n",
      "    \"concepts\": [\n",
      "      {\n",
      "        \"name\": \"人工智能\",\n",
      "        \"code\": \"CLS80207\",\n",
      "        \"relevance\": 0.8\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"REITs\",\n",
      "        \"code\": \"CLS80464\",\n",
      "        \"relevance\": 0.8\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"人形机器人\",\n",
      "        \"code\": \"CLS82064\",\n",
      "        \"relevance\": 0.8\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 1) 载入词典\n",
    "companies, concepts, industries = load_taxonomies(\n",
    "    \"source/industry/company-listcsv.csv\",\n",
    "    \"source/industry/concept-list.csv\",\n",
    "    \"source/industry/industry-list.csv\"\n",
    ")\n",
    "\n",
    "# 2) 建公司索引\n",
    "full_name_set, norm_to_full, norm_list = build_company_index(companies)\n",
    "\n",
    "# 3) 单条测试（只用 content）\n",
    "content = df.loc[0, \"content\"]\n",
    "\n",
    "entities = extract_entities_from_content(\n",
    "    call_dify_api=test_qwen.call_dify_api,   # 你现有接口\n",
    "    content=content,\n",
    "    companies=companies,\n",
    "    concepts=concepts,\n",
    "    industries=industries,\n",
    "    full_name_set=full_name_set,\n",
    "    norm_to_full=norm_to_full,\n",
    "    norm_list=norm_list\n",
    ")\n",
    "\n",
    "print(json.dumps({\"entities\": entities}, ensure_ascii=False, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
